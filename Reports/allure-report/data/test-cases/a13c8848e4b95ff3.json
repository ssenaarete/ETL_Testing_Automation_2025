{"uid":"a13c8848e4b95ff3","name":"test_datacompleteness_StoS_validation","fullName":"tests.test_smoke_suite#test_datacompleteness_StoS_validation","historyId":"4e0f36ad47345c8b8e4221d04ce42d7b","time":{"start":1759842538535,"stop":1759842542587,"duration":4052},"status":"failed","statusMessage":"AssertionError: ❌ Data completeness check failed for source_doctors ↔ stage_doctors. Missing rows = 40016","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x000001BE3CB9EEA0>\nstage_db = <utils.db_helper.DBHelper object at 0x000001BE3CB9F5C0>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001BE3CBF2AD0>\n\n    @pytest.mark.skipif(not should_run(\"data_completeness_validation_SourceToStage\"), reason=\"Marked N in Excel\")\n    def test_datacompleteness_StoS_validation(source_db, stage_db,report_helper):\n        cv = Validation_SourceToStage()\n>       cv.run(source_db, stage_db,report_helper)\n\ntests\\test_smoke_suite.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <src.data_completeness_validation.Validation_SourceToStage object at 0x000001BE3C8782F0>\nsource_db = <utils.db_helper.DBHelper object at 0x000001BE3CB9EEA0>\nstage_db = <utils.db_helper.DBHelper object at 0x000001BE3CB9F5C0>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001BE3CBF2AD0>\n\n    def run(self, source_db, stage_db, report_helper):\n        df = pd.read_excel(self.excel_path, sheet_name=\"Table_Mapping\")\n    \n        results = []\n        failed_checks = []  # track failures\n    \n        for _, row in df.iterrows():\n            source_table = row[\"source_table\"]\n            stage_table = row[\"stage_table\"]\n    \n            common_columns = self.get_common_columns(source_db, stage_db, source_table, stage_table)\n            logging.info(f\"Common columns for {source_table} ↔ {stage_table}: {common_columns}\")\n    \n            # ✅ Assertion: must have common columns\n            assert common_columns, f\"❌ No common columns found for {source_table} ↔ {stage_table}\"\n    \n            completeness_query = f\"\"\"\n                SELECT COUNT(*) AS Missing_Count\n                FROM (\n                    SELECT {common_columns}\n                    FROM {self.config.get(\"SOURCEDB\", \"database\")}.dbo.{source_table}\n                    EXCEPT\n                    SELECT {common_columns}\n                    FROM {self.config.get(\"STAGEDB\", \"database\")}.dbo.{stage_table}\n                ) AS diff\n            \"\"\"\n    \n            logging.info(f\"Running completeness check: {source_table} → {stage_table}\")\n            raw_result = source_db.execute_query(completeness_query)\n    \n            missing_count = raw_result[0][0] if raw_result else 0\n    \n            # ✅ Assertion: missing count should be 0\n            # assert missing_count == 0, (\n            #     f\"❌ Data completeness check failed for {source_table} ↔ {stage_table}. \"\n            #     f\"Missing rows = {missing_count}\"\n            # )\n    \n            is_check_passed = missing_count == 0\n    \n            results.append({\n                \"Source_DB\": self.config.get(\"SOURCEDB\", \"database\"),\n                \"Source_Table\": source_table,\n                \"Stage_DB\": self.config.get(\"STAGEDB\", \"database\"),\n                \"Stage_Table\": stage_table,\n                \"Common_Columns\": common_columns,\n                \"Data_Missing_Count\": missing_count,\n                \"IsCheckPassed\": is_check_passed\n            })\n    \n            if not is_check_passed:\n                failed_checks.append(f\"❌ Data completeness check failed for {source_table} ↔ {stage_table}. Missing rows = {missing_count}\")\n    \n            # assert is_check_passed, f\"❌ Data completeness check failed for {source_table} ↔ {stage_table}\"\n    \n        # ✅ Save & print report\n        report_helper.save_report(results, test_type=\"Data_Completeness_Source_to_Stage\")\n        # report_helper.print_validation_report_Source_to_Stage(results)\n    \n        # ✅ Fail test at the end (after report generation)\n>       assert not failed_checks, \"\\n\".join(failed_checks)\n               ^^^^^^^^^^^^^^^^^\nE       AssertionError: ❌ Data completeness check failed for source_doctors ↔ stage_doctors. Missing rows = 40016\n\nsrc\\data_completeness_validation.py:104: AssertionError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"_session_faker","time":{"start":1759842538097,"stop":1759842538197,"duration":100},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"source_db","time":{"start":1759842538532,"stop":1759842538533,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"stage_db","time":{"start":1759842538533,"stop":1759842538533,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"report_helper","time":{"start":1759842538534,"stop":1759842538535,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false}],"testStage":{"status":"failed","statusMessage":"AssertionError: ❌ Data completeness check failed for source_doctors ↔ stage_doctors. Missing rows = 40016","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x000001BE3CB9EEA0>\nstage_db = <utils.db_helper.DBHelper object at 0x000001BE3CB9F5C0>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001BE3CBF2AD0>\n\n    @pytest.mark.skipif(not should_run(\"data_completeness_validation_SourceToStage\"), reason=\"Marked N in Excel\")\n    def test_datacompleteness_StoS_validation(source_db, stage_db,report_helper):\n        cv = Validation_SourceToStage()\n>       cv.run(source_db, stage_db,report_helper)\n\ntests\\test_smoke_suite.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <src.data_completeness_validation.Validation_SourceToStage object at 0x000001BE3C8782F0>\nsource_db = <utils.db_helper.DBHelper object at 0x000001BE3CB9EEA0>\nstage_db = <utils.db_helper.DBHelper object at 0x000001BE3CB9F5C0>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001BE3CBF2AD0>\n\n    def run(self, source_db, stage_db, report_helper):\n        df = pd.read_excel(self.excel_path, sheet_name=\"Table_Mapping\")\n    \n        results = []\n        failed_checks = []  # track failures\n    \n        for _, row in df.iterrows():\n            source_table = row[\"source_table\"]\n            stage_table = row[\"stage_table\"]\n    \n            common_columns = self.get_common_columns(source_db, stage_db, source_table, stage_table)\n            logging.info(f\"Common columns for {source_table} ↔ {stage_table}: {common_columns}\")\n    \n            # ✅ Assertion: must have common columns\n            assert common_columns, f\"❌ No common columns found for {source_table} ↔ {stage_table}\"\n    \n            completeness_query = f\"\"\"\n                SELECT COUNT(*) AS Missing_Count\n                FROM (\n                    SELECT {common_columns}\n                    FROM {self.config.get(\"SOURCEDB\", \"database\")}.dbo.{source_table}\n                    EXCEPT\n                    SELECT {common_columns}\n                    FROM {self.config.get(\"STAGEDB\", \"database\")}.dbo.{stage_table}\n                ) AS diff\n            \"\"\"\n    \n            logging.info(f\"Running completeness check: {source_table} → {stage_table}\")\n            raw_result = source_db.execute_query(completeness_query)\n    \n            missing_count = raw_result[0][0] if raw_result else 0\n    \n            # ✅ Assertion: missing count should be 0\n            # assert missing_count == 0, (\n            #     f\"❌ Data completeness check failed for {source_table} ↔ {stage_table}. \"\n            #     f\"Missing rows = {missing_count}\"\n            # )\n    \n            is_check_passed = missing_count == 0\n    \n            results.append({\n                \"Source_DB\": self.config.get(\"SOURCEDB\", \"database\"),\n                \"Source_Table\": source_table,\n                \"Stage_DB\": self.config.get(\"STAGEDB\", \"database\"),\n                \"Stage_Table\": stage_table,\n                \"Common_Columns\": common_columns,\n                \"Data_Missing_Count\": missing_count,\n                \"IsCheckPassed\": is_check_passed\n            })\n    \n            if not is_check_passed:\n                failed_checks.append(f\"❌ Data completeness check failed for {source_table} ↔ {stage_table}. Missing rows = {missing_count}\")\n    \n            # assert is_check_passed, f\"❌ Data completeness check failed for {source_table} ↔ {stage_table}\"\n    \n        # ✅ Save & print report\n        report_helper.save_report(results, test_type=\"Data_Completeness_Source_to_Stage\")\n        # report_helper.print_validation_report_Source_to_Stage(results)\n    \n        # ✅ Fail test at the end (after report generation)\n>       assert not failed_checks, \"\\n\".join(failed_checks)\n               ^^^^^^^^^^^^^^^^^\nE       AssertionError: ❌ Data completeness check failed for source_doctors ↔ stage_doctors. Missing rows = 40016\n\nsrc\\data_completeness_validation.py:104: AssertionError","steps":[],"attachments":[{"uid":"856ce76ec1715eba","name":"stdout","source":"856ce76ec1715eba.txt","type":"text/plain","size":108}],"parameters":[],"attachmentStep":false,"hasContent":true,"stepsCount":0,"attachmentsCount":1,"shouldDisplayMessage":true},"afterStages":[{"name":"stage_db::0","time":{"start":1759842542784,"stop":1759842542785,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"source_db::0","time":{"start":1759842542785,"stop":1759842542786,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false}],"labels":[{"name":"parentSuite","value":"tests"},{"name":"suite","value":"test_smoke_suite"},{"name":"host","value":"INATS-LTP-066"},{"name":"thread","value":"37152-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"tests.test_smoke_suite"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":true,"retry":true,"extra":{"categories":[],"tags":[]},"source":"a13c8848e4b95ff3.json","parameterValues":[]}