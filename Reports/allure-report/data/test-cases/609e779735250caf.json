{"uid":"609e779735250caf","name":"test_count_validation","fullName":"tests.test_smoke_suite#test_count_validation","historyId":"6307ed8e30228b676f72eaa7d082e9f2","time":{"start":1756977858020,"stop":1756977858160,"duration":140},"status":"failed","statusMessage":"AssertionError: ❌ Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 78, 'Status': 'FAIL'}]","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x000001FC60717620>\nstage_db = <utils.db_helper.DBHelper object at 0x000001FC6091C690>\ntarget_db = <utils.db_helper.DBHelper object at 0x000001FC6091D310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001FC60717A10>\n\n    @pytest.mark.skipif(not should_run(\"count_validation\"), reason=\"Marked N in Excel\")\n    def test_count_validation(source_db, stage_db, target_db,report_helper):\n        cv = CountValidation()\n>       cv.run(source_db, stage_db, target_db,report_helper)\n\ntests\\test_smoke_suite.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <src.count_validation.CountValidation object at 0x000001FC60974050>\nsource_db = <utils.db_helper.DBHelper object at 0x000001FC60717620>\nstage_db = <utils.db_helper.DBHelper object at 0x000001FC6091C690>\ntarget_db = <utils.db_helper.DBHelper object at 0x000001FC6091D310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001FC60717A10>\n\n    def run(self, source_db, stage_db, target_db, report_helper):\n        # Always load \"Table_Mapping\" sheet from the Excel file\n        df = pd.read_excel(self.excel_file, sheet_name=\"Table_Mapping\", engine=\"openpyxl\")\n    \n        logging.info(f\"Excel Columns Found: {df.columns.tolist()}\")\n        print(\"DEBUG: Columns in Excel →\", df.columns.tolist())\n    \n        results = []\n    \n        def normalize(val):\n            if isinstance(val, list) and val and isinstance(val[0], (tuple, list)):\n                return val[0][0]\n            elif isinstance(val, (list, tuple)) and val:\n                return val[0]\n            return val\n    \n        for _, row in df.iterrows():\n            source_table, stage_table, target_table = (\n                row[\"source_table\"],\n                row[\"stage_table\"],\n                row[\"target_table\"]\n            )\n    \n            queries = {\n                \"Source\": f\"SELECT COUNT(*) FROM {source_table}\",\n                \"Stage\": f\"SELECT COUNT(*) FROM {stage_table}\",\n                \"Target\": f\"SELECT COUNT(*) FROM {target_table}\"\n            }\n    \n            logging.info(f\"Validating counts: {source_table} ↔ {stage_table} ↔ {target_table}\")\n    \n            counts = {\n                \"Source\": normalize(source_db.execute_query(queries[\"Source\"])),\n                \"Stage\": normalize(stage_db.execute_query(queries[\"Stage\"])),\n                \"Target\": normalize(target_db.execute_query(queries[\"Target\"])),\n            }\n    \n            status = \"PASS\" if (counts[\"Source\"] == counts[\"Stage\"] == counts[\"Target\"]) else \"FAIL\"\n    \n            results.append({\n                \"Source_Table\": source_table, \"Source_Count\": counts[\"Source\"],\n                \"Stage_Table\": stage_table, \"Stage_Count\": counts[\"Stage\"],\n                \"Target_Table\": target_table, \"Target_Count\": counts[\"Target\"],\n                \"Status\": status\n            })\n    \n            logging.info(\n                f\"{source_table}({counts['Source']}) ↔ \"\n                f\"{stage_table}({counts['Stage']}) ↔ \"\n                f\"{target_table}({counts['Target']}) → {status}\"\n            )\n    \n        # Save and assert at once\n        report_helper.save_report(results, test_type=\"Count_Check\")\n        # report_helper.print_validation_report_count(results)\n    \n        failed = [r for r in results if r[\"Status\"] == \"FAIL\"]\n>       assert not failed, f\"❌ Row count mismatches found: {failed}\"\n               ^^^^^^^^^^\nE       AssertionError: ❌ Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 78, 'Status': 'FAIL'}]\n\nsrc\\count_validation.py:71: AssertionError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"source_db","time":{"start":1756977857632,"stop":1756977857893,"duration":261},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"stepsCount":0,"hasContent":false,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"stage_db","time":{"start":1756977857893,"stop":1756977857947,"duration":54},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"stepsCount":0,"hasContent":false,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"target_db","time":{"start":1756977857947,"stop":1756977858017,"duration":70},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"stepsCount":0,"hasContent":false,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"report_helper","time":{"start":1756977858017,"stop":1756977858019,"duration":2},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"stepsCount":0,"hasContent":false,"attachmentsCount":0,"shouldDisplayMessage":false}],"testStage":{"status":"failed","statusMessage":"AssertionError: ❌ Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 78, 'Status': 'FAIL'}]","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x000001FC60717620>\nstage_db = <utils.db_helper.DBHelper object at 0x000001FC6091C690>\ntarget_db = <utils.db_helper.DBHelper object at 0x000001FC6091D310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001FC60717A10>\n\n    @pytest.mark.skipif(not should_run(\"count_validation\"), reason=\"Marked N in Excel\")\n    def test_count_validation(source_db, stage_db, target_db,report_helper):\n        cv = CountValidation()\n>       cv.run(source_db, stage_db, target_db,report_helper)\n\ntests\\test_smoke_suite.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <src.count_validation.CountValidation object at 0x000001FC60974050>\nsource_db = <utils.db_helper.DBHelper object at 0x000001FC60717620>\nstage_db = <utils.db_helper.DBHelper object at 0x000001FC6091C690>\ntarget_db = <utils.db_helper.DBHelper object at 0x000001FC6091D310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001FC60717A10>\n\n    def run(self, source_db, stage_db, target_db, report_helper):\n        # Always load \"Table_Mapping\" sheet from the Excel file\n        df = pd.read_excel(self.excel_file, sheet_name=\"Table_Mapping\", engine=\"openpyxl\")\n    \n        logging.info(f\"Excel Columns Found: {df.columns.tolist()}\")\n        print(\"DEBUG: Columns in Excel →\", df.columns.tolist())\n    \n        results = []\n    \n        def normalize(val):\n            if isinstance(val, list) and val and isinstance(val[0], (tuple, list)):\n                return val[0][0]\n            elif isinstance(val, (list, tuple)) and val:\n                return val[0]\n            return val\n    \n        for _, row in df.iterrows():\n            source_table, stage_table, target_table = (\n                row[\"source_table\"],\n                row[\"stage_table\"],\n                row[\"target_table\"]\n            )\n    \n            queries = {\n                \"Source\": f\"SELECT COUNT(*) FROM {source_table}\",\n                \"Stage\": f\"SELECT COUNT(*) FROM {stage_table}\",\n                \"Target\": f\"SELECT COUNT(*) FROM {target_table}\"\n            }\n    \n            logging.info(f\"Validating counts: {source_table} ↔ {stage_table} ↔ {target_table}\")\n    \n            counts = {\n                \"Source\": normalize(source_db.execute_query(queries[\"Source\"])),\n                \"Stage\": normalize(stage_db.execute_query(queries[\"Stage\"])),\n                \"Target\": normalize(target_db.execute_query(queries[\"Target\"])),\n            }\n    \n            status = \"PASS\" if (counts[\"Source\"] == counts[\"Stage\"] == counts[\"Target\"]) else \"FAIL\"\n    \n            results.append({\n                \"Source_Table\": source_table, \"Source_Count\": counts[\"Source\"],\n                \"Stage_Table\": stage_table, \"Stage_Count\": counts[\"Stage\"],\n                \"Target_Table\": target_table, \"Target_Count\": counts[\"Target\"],\n                \"Status\": status\n            })\n    \n            logging.info(\n                f\"{source_table}({counts['Source']}) ↔ \"\n                f\"{stage_table}({counts['Stage']}) ↔ \"\n                f\"{target_table}({counts['Target']}) → {status}\"\n            )\n    \n        # Save and assert at once\n        report_helper.save_report(results, test_type=\"Count_Check\")\n        # report_helper.print_validation_report_count(results)\n    \n        failed = [r for r in results if r[\"Status\"] == \"FAIL\"]\n>       assert not failed, f\"❌ Row count mismatches found: {failed}\"\n               ^^^^^^^^^^\nE       AssertionError: ❌ Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 78, 'Status': 'FAIL'}]\n\nsrc\\count_validation.py:71: AssertionError","steps":[],"attachments":[{"uid":"7fb4c77932617881","name":"stdout","source":"7fb4c77932617881.txt","type":"text/plain","size":162}],"parameters":[],"attachmentStep":false,"stepsCount":0,"hasContent":true,"attachmentsCount":1,"shouldDisplayMessage":true},"afterStages":[{"name":"target_db::0","time":{"start":1756977858635,"stop":1756977858637,"duration":2},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"stepsCount":0,"hasContent":false,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"stage_db::0","time":{"start":1756977858638,"stop":1756977858640,"duration":2},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"stepsCount":0,"hasContent":false,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"source_db::0","time":{"start":1756977858641,"stop":1756977858643,"duration":2},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"stepsCount":0,"hasContent":false,"attachmentsCount":0,"shouldDisplayMessage":false}],"labels":[{"name":"parentSuite","value":"tests"},{"name":"suite","value":"test_smoke_suite"},{"name":"host","value":"INATS-LTP-066"},{"name":"thread","value":"13820-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"tests.test_smoke_suite"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Product defects","matchedStatuses":[]}],"tags":[]},"source":"609e779735250caf.json","parameterValues":[]}