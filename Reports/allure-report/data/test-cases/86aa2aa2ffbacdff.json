{"uid":"86aa2aa2ffbacdff","name":"test_count_validation","fullName":"tests.test_smoke_suite#test_count_validation","historyId":"6307ed8e30228b676f72eaa7d082e9f2","time":{"start":1756758959421,"stop":1756758959468,"duration":47},"status":"failed","statusMessage":"AssertionError: Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 78, 'Status': 'FAIL'}]","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x0000022C5E2F7CB0>\nstage_db = <utils.db_helper.DBHelper object at 0x0000022C5E4F8690>\ntarget_db = <utils.db_helper.DBHelper object at 0x0000022C5E4F9310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x0000022C5E2F7E00>\n\n    @pytest.mark.skipif(not should_run(\"count_validation\"), reason=\"Marked N in Excel\")\n    def test_count_validation(source_db, stage_db, target_db,report_helper):\n        cv = CountValidation()\n>       cv.run(source_db, stage_db, target_db,report_helper)\n\ntests\\test_smoke_suite.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <src.count_validation.CountValidation object at 0x0000022C5E5281A0>\nsource_db = <utils.db_helper.DBHelper object at 0x0000022C5E2F7CB0>\nstage_db = <utils.db_helper.DBHelper object at 0x0000022C5E4F8690>\ntarget_db = <utils.db_helper.DBHelper object at 0x0000022C5E4F9310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x0000022C5E2F7E00>\n\n    def run(self, source_db, stage_db, target_db, report_helper):\n        # Always load \"Table_Mapping\" sheet from the Excel file\n        df = pd.read_excel(self.excel_file, sheet_name=\"Table_Mapping\", engine=\"openpyxl\")\n    \n        logging.info(f\"Excel Columns Found: {df.columns.tolist()}\")\n        print(\"DEBUG: Columns in Excel →\", df.columns.tolist())\n    \n        results = []\n    \n        def normalize(val):\n            if isinstance(val, list) and val and isinstance(val[0], (tuple, list)):\n                return val[0][0]\n            elif isinstance(val, (list, tuple)) and val:\n                return val[0]\n            return val\n    \n        for _, row in df.iterrows():\n            source_table, stage_table, target_table = (\n                row[\"source_table\"],\n                row[\"stage_table\"],\n                row[\"target_table\"]\n            )\n    \n            queries = {\n                \"Source\": f\"SELECT COUNT(*) FROM {source_table}\",\n                \"Stage\": f\"SELECT COUNT(*) FROM {stage_table}\",\n                \"Target\": f\"SELECT COUNT(*) FROM {target_table}\"\n            }\n    \n            logging.info(f\"Validating counts: {source_table} ↔ {stage_table} ↔ {target_table}\")\n    \n            counts = {\n                \"Source\": normalize(source_db.execute_query(queries[\"Source\"])),\n                \"Stage\": normalize(stage_db.execute_query(queries[\"Stage\"])),\n                \"Target\": normalize(target_db.execute_query(queries[\"Target\"])),\n            }\n    \n            status = \"PASS\" if (counts[\"Source\"] == counts[\"Stage\"] == counts[\"Target\"]) else \"FAIL\"\n    \n            results.append({\n                \"Source_Table\": source_table, \"Source_Count\": counts[\"Source\"],\n                \"Stage_Table\": stage_table, \"Stage_Count\": counts[\"Stage\"],\n                \"Target_Table\": target_table, \"Target_Count\": counts[\"Target\"],\n                \"Status\": status\n            })\n    \n            logging.info(\n                f\"{source_table}({counts['Source']}) ↔ \"\n                f\"{stage_table}({counts['Stage']}) ↔ \"\n                f\"{target_table}({counts['Target']}) → {status}\"\n            )\n    \n        # Save and assert at once\n        report_helper.save_report(results, test_type=\"Count_Check\")\n        # report_helper.print_validation_report_count(results)\n    \n        failed = [r for r in results if r[\"Status\"] == \"FAIL\"]\n>       assert not failed, f\"Row count mismatches found: {failed}\"\n               ^^^^^^^^^^\nE       AssertionError: Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 78, 'Status': 'FAIL'}]\n\nsrc\\count_validation.py:71: AssertionError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"source_db","time":{"start":1756758959175,"stop":1756758959348,"duration":173},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"attachmentStep":false,"stepsCount":0},{"name":"stage_db","time":{"start":1756758959349,"stop":1756758959384,"duration":35},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"attachmentStep":false,"stepsCount":0},{"name":"target_db","time":{"start":1756758959384,"stop":1756758959419,"duration":35},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"attachmentStep":false,"stepsCount":0},{"name":"report_helper","time":{"start":1756758959419,"stop":1756758959420,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"attachmentStep":false,"stepsCount":0}],"testStage":{"status":"failed","statusMessage":"AssertionError: Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 78, 'Status': 'FAIL'}]","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x0000022C5E2F7CB0>\nstage_db = <utils.db_helper.DBHelper object at 0x0000022C5E4F8690>\ntarget_db = <utils.db_helper.DBHelper object at 0x0000022C5E4F9310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x0000022C5E2F7E00>\n\n    @pytest.mark.skipif(not should_run(\"count_validation\"), reason=\"Marked N in Excel\")\n    def test_count_validation(source_db, stage_db, target_db,report_helper):\n        cv = CountValidation()\n>       cv.run(source_db, stage_db, target_db,report_helper)\n\ntests\\test_smoke_suite.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <src.count_validation.CountValidation object at 0x0000022C5E5281A0>\nsource_db = <utils.db_helper.DBHelper object at 0x0000022C5E2F7CB0>\nstage_db = <utils.db_helper.DBHelper object at 0x0000022C5E4F8690>\ntarget_db = <utils.db_helper.DBHelper object at 0x0000022C5E4F9310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x0000022C5E2F7E00>\n\n    def run(self, source_db, stage_db, target_db, report_helper):\n        # Always load \"Table_Mapping\" sheet from the Excel file\n        df = pd.read_excel(self.excel_file, sheet_name=\"Table_Mapping\", engine=\"openpyxl\")\n    \n        logging.info(f\"Excel Columns Found: {df.columns.tolist()}\")\n        print(\"DEBUG: Columns in Excel →\", df.columns.tolist())\n    \n        results = []\n    \n        def normalize(val):\n            if isinstance(val, list) and val and isinstance(val[0], (tuple, list)):\n                return val[0][0]\n            elif isinstance(val, (list, tuple)) and val:\n                return val[0]\n            return val\n    \n        for _, row in df.iterrows():\n            source_table, stage_table, target_table = (\n                row[\"source_table\"],\n                row[\"stage_table\"],\n                row[\"target_table\"]\n            )\n    \n            queries = {\n                \"Source\": f\"SELECT COUNT(*) FROM {source_table}\",\n                \"Stage\": f\"SELECT COUNT(*) FROM {stage_table}\",\n                \"Target\": f\"SELECT COUNT(*) FROM {target_table}\"\n            }\n    \n            logging.info(f\"Validating counts: {source_table} ↔ {stage_table} ↔ {target_table}\")\n    \n            counts = {\n                \"Source\": normalize(source_db.execute_query(queries[\"Source\"])),\n                \"Stage\": normalize(stage_db.execute_query(queries[\"Stage\"])),\n                \"Target\": normalize(target_db.execute_query(queries[\"Target\"])),\n            }\n    \n            status = \"PASS\" if (counts[\"Source\"] == counts[\"Stage\"] == counts[\"Target\"]) else \"FAIL\"\n    \n            results.append({\n                \"Source_Table\": source_table, \"Source_Count\": counts[\"Source\"],\n                \"Stage_Table\": stage_table, \"Stage_Count\": counts[\"Stage\"],\n                \"Target_Table\": target_table, \"Target_Count\": counts[\"Target\"],\n                \"Status\": status\n            })\n    \n            logging.info(\n                f\"{source_table}({counts['Source']}) ↔ \"\n                f\"{stage_table}({counts['Stage']}) ↔ \"\n                f\"{target_table}({counts['Target']}) → {status}\"\n            )\n    \n        # Save and assert at once\n        report_helper.save_report(results, test_type=\"Count_Check\")\n        # report_helper.print_validation_report_count(results)\n    \n        failed = [r for r in results if r[\"Status\"] == \"FAIL\"]\n>       assert not failed, f\"Row count mismatches found: {failed}\"\n               ^^^^^^^^^^\nE       AssertionError: Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 78, 'Status': 'FAIL'}]\n\nsrc\\count_validation.py:71: AssertionError","steps":[],"attachments":[{"uid":"54937f42433cdc24","name":"stdout","source":"54937f42433cdc24.txt","type":"text/plain","size":162}],"parameters":[],"shouldDisplayMessage":true,"attachmentsCount":1,"hasContent":true,"attachmentStep":false,"stepsCount":0},"afterStages":[{"name":"target_db::0","time":{"start":1756758959645,"stop":1756758959647,"duration":2},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"attachmentStep":false,"stepsCount":0},{"name":"stage_db::0","time":{"start":1756758959649,"stop":1756758959649,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"attachmentStep":false,"stepsCount":0},{"name":"source_db::0","time":{"start":1756758959650,"stop":1756758959651,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"attachmentStep":false,"stepsCount":0}],"labels":[{"name":"parentSuite","value":"tests"},{"name":"suite","value":"test_smoke_suite"},{"name":"host","value":"INATS-LTP-066"},{"name":"thread","value":"37384-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"tests.test_smoke_suite"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"ETL Validation Errors","messageRegex":".*Row count mismatch.*","matchedStatuses":["failed"]}],"tags":[]},"source":"86aa2aa2ffbacdff.json","parameterValues":[]}