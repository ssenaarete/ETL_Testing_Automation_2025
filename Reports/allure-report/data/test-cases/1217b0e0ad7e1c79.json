{"uid":"1217b0e0ad7e1c79","name":"test_count_validation","fullName":"tests.test_smoke_suite#test_count_validation","historyId":"6307ed8e30228b676f72eaa7d082e9f2","time":{"start":1759134093480,"stop":1759134093621,"duration":141},"status":"failed","statusMessage":"AssertionError: ❌ Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 79, 'Status': 'FAIL'}]","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x000002C6FCD06F90>\nstage_db = <utils.db_helper.DBHelper object at 0x000002C6FCEFCCD0>\ntarget_db = <utils.db_helper.DBHelper object at 0x000002C6FCEFD310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000002C6FCD06E40>\n\n    @pytest.mark.skipif(not should_run(\"count_validation\"), reason=\"Marked N in Excel\")\n    def test_count_validation(source_db, stage_db, target_db,report_helper):\n        cv = CountValidation()\n>       cv.run(source_db, stage_db, target_db,report_helper)\n\ntests\\test_smoke_suite.py:78: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.count_validation.CountValidation object at 0x000002C6FCD07620>\nsource_db = <utils.db_helper.DBHelper object at 0x000002C6FCD06F90>\nstage_db = <utils.db_helper.DBHelper object at 0x000002C6FCEFCCD0>\ntarget_db = <utils.db_helper.DBHelper object at 0x000002C6FCEFD310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000002C6FCD06E40>\n\n    def run(self, source_db, stage_db, target_db, report_helper):\n        # Always load \"Table_Mapping\" sheet from the Excel file\n        df = pd.read_excel(self.excel_file, sheet_name=\"Table_Mapping\", engine=\"openpyxl\")\n    \n        logging.info(f\"Excel Columns Found: {df.columns.tolist()}\")\n        print(\"DEBUG: Columns in Excel →\", df.columns.tolist())\n    \n        results = []\n    \n        def normalize(val):\n            if isinstance(val, list) and val and isinstance(val[0], (tuple, list)):\n                return val[0][0]\n            elif isinstance(val, (list, tuple)) and val:\n                return val[0]\n            return val\n    \n        for _, row in df.iterrows():\n            source_table, stage_table, target_table = (\n                row[\"source_table\"],\n                row[\"stage_table\"],\n                row[\"target_table\"]\n            )\n    \n            queries = {\n                \"Source\": f\"SELECT COUNT(*) FROM {source_table}\",\n                \"Stage\": f\"SELECT COUNT(*) FROM {stage_table}\",\n                \"Target\": f\"SELECT COUNT(*) FROM {target_table}\"\n            }\n    \n            logging.info(f\"Validating counts: {source_table} ↔ {stage_table} ↔ {target_table}\")\n    \n            counts = {\n                \"Source\": normalize(source_db.execute_query(queries[\"Source\"])),\n                \"Stage\": normalize(stage_db.execute_query(queries[\"Stage\"])),\n                \"Target\": normalize(target_db.execute_query(queries[\"Target\"])),\n            }\n    \n            status = \"PASS\" if (counts[\"Source\"] == counts[\"Stage\"] == counts[\"Target\"]) else \"FAIL\"\n    \n            results.append({\n                \"Source_Table\": source_table, \"Source_Count\": counts[\"Source\"],\n                \"Stage_Table\": stage_table, \"Stage_Count\": counts[\"Stage\"],\n                \"Target_Table\": target_table, \"Target_Count\": counts[\"Target\"],\n                \"Status\": status\n            })\n    \n            logging.info(\n                f\"{source_table}({counts['Source']}) ↔ \"\n                f\"{stage_table}({counts['Stage']}) ↔ \"\n                f\"{target_table}({counts['Target']}) → {status}\"\n            )\n    \n        # Save and assert at once\n        report_helper.save_report(results, test_type=\"Count_Check\")\n        # report_helper.print_validation_report_count(results)\n    \n        failed = [r for r in results if r[\"Status\"] == \"FAIL\"]\n>       assert not failed, f\"❌ Row count mismatches found: {failed}\"\n               ^^^^^^^^^^\nE       AssertionError: ❌ Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 79, 'Status': 'FAIL'}]\n\nsrc\\count_validation.py:71: AssertionError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"source_db","time":{"start":1759134093003,"stop":1759134093343,"duration":340},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"stepsCount":0,"attachmentStep":false},{"name":"stage_db","time":{"start":1759134093343,"stop":1759134093421,"duration":78},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"stepsCount":0,"attachmentStep":false},{"name":"target_db","time":{"start":1759134093421,"stop":1759134093477,"duration":56},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"stepsCount":0,"attachmentStep":false},{"name":"report_helper","time":{"start":1759134093477,"stop":1759134093479,"duration":2},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"stepsCount":0,"attachmentStep":false}],"testStage":{"status":"failed","statusMessage":"AssertionError: ❌ Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 79, 'Status': 'FAIL'}]","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x000002C6FCD06F90>\nstage_db = <utils.db_helper.DBHelper object at 0x000002C6FCEFCCD0>\ntarget_db = <utils.db_helper.DBHelper object at 0x000002C6FCEFD310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000002C6FCD06E40>\n\n    @pytest.mark.skipif(not should_run(\"count_validation\"), reason=\"Marked N in Excel\")\n    def test_count_validation(source_db, stage_db, target_db,report_helper):\n        cv = CountValidation()\n>       cv.run(source_db, stage_db, target_db,report_helper)\n\ntests\\test_smoke_suite.py:78: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <src.count_validation.CountValidation object at 0x000002C6FCD07620>\nsource_db = <utils.db_helper.DBHelper object at 0x000002C6FCD06F90>\nstage_db = <utils.db_helper.DBHelper object at 0x000002C6FCEFCCD0>\ntarget_db = <utils.db_helper.DBHelper object at 0x000002C6FCEFD310>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000002C6FCD06E40>\n\n    def run(self, source_db, stage_db, target_db, report_helper):\n        # Always load \"Table_Mapping\" sheet from the Excel file\n        df = pd.read_excel(self.excel_file, sheet_name=\"Table_Mapping\", engine=\"openpyxl\")\n    \n        logging.info(f\"Excel Columns Found: {df.columns.tolist()}\")\n        print(\"DEBUG: Columns in Excel →\", df.columns.tolist())\n    \n        results = []\n    \n        def normalize(val):\n            if isinstance(val, list) and val and isinstance(val[0], (tuple, list)):\n                return val[0][0]\n            elif isinstance(val, (list, tuple)) and val:\n                return val[0]\n            return val\n    \n        for _, row in df.iterrows():\n            source_table, stage_table, target_table = (\n                row[\"source_table\"],\n                row[\"stage_table\"],\n                row[\"target_table\"]\n            )\n    \n            queries = {\n                \"Source\": f\"SELECT COUNT(*) FROM {source_table}\",\n                \"Stage\": f\"SELECT COUNT(*) FROM {stage_table}\",\n                \"Target\": f\"SELECT COUNT(*) FROM {target_table}\"\n            }\n    \n            logging.info(f\"Validating counts: {source_table} ↔ {stage_table} ↔ {target_table}\")\n    \n            counts = {\n                \"Source\": normalize(source_db.execute_query(queries[\"Source\"])),\n                \"Stage\": normalize(stage_db.execute_query(queries[\"Stage\"])),\n                \"Target\": normalize(target_db.execute_query(queries[\"Target\"])),\n            }\n    \n            status = \"PASS\" if (counts[\"Source\"] == counts[\"Stage\"] == counts[\"Target\"]) else \"FAIL\"\n    \n            results.append({\n                \"Source_Table\": source_table, \"Source_Count\": counts[\"Source\"],\n                \"Stage_Table\": stage_table, \"Stage_Count\": counts[\"Stage\"],\n                \"Target_Table\": target_table, \"Target_Count\": counts[\"Target\"],\n                \"Status\": status\n            })\n    \n            logging.info(\n                f\"{source_table}({counts['Source']}) ↔ \"\n                f\"{stage_table}({counts['Stage']}) ↔ \"\n                f\"{target_table}({counts['Target']}) → {status}\"\n            )\n    \n        # Save and assert at once\n        report_helper.save_report(results, test_type=\"Count_Check\")\n        # report_helper.print_validation_report_count(results)\n    \n        failed = [r for r in results if r[\"Status\"] == \"FAIL\"]\n>       assert not failed, f\"❌ Row count mismatches found: {failed}\"\n               ^^^^^^^^^^\nE       AssertionError: ❌ Row count mismatches found: [{'Source_Table': 'source_doctors', 'Source_Count': 10, 'Stage_Table': 'stage_doctors', 'Stage_Count': 12, 'Target_Table': 'target_doctors', 'Target_Count': 11, 'Status': 'FAIL'}, {'Source_Table': 'source_patients', 'Source_Count': 77, 'Stage_Table': 'stage_patients', 'Stage_Count': 78, 'Target_Table': 'target_patients', 'Target_Count': 79, 'Status': 'FAIL'}]\n\nsrc\\count_validation.py:71: AssertionError","steps":[],"attachments":[{"uid":"a380ea6e3fe358ca","name":"stdout","source":"a380ea6e3fe358ca.txt","type":"text/plain","size":194}],"parameters":[],"shouldDisplayMessage":true,"attachmentsCount":1,"hasContent":true,"stepsCount":0,"attachmentStep":false},"afterStages":[{"name":"target_db::0","time":{"start":1759134094066,"stop":1759134094069,"duration":3},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"stepsCount":0,"attachmentStep":false},{"name":"stage_db::0","time":{"start":1759134094071,"stop":1759134094072,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"stepsCount":0,"attachmentStep":false},{"name":"source_db::0","time":{"start":1759134094073,"stop":1759134094074,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"attachmentsCount":0,"hasContent":false,"stepsCount":0,"attachmentStep":false}],"labels":[{"name":"parentSuite","value":"tests"},{"name":"suite","value":"test_smoke_suite"},{"name":"host","value":"INATS-LTP-066"},{"name":"thread","value":"33180-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"tests.test_smoke_suite"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":true,"retry":true,"extra":{"categories":[],"tags":[]},"source":"1217b0e0ad7e1c79.json","parameterValues":[]}