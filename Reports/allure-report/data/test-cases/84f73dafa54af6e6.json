{"uid":"84f73dafa54af6e6","name":"test_scd_StoS_validation","fullName":"tests.test_smoke_suite#test_scd_StoS_validation","historyId":"2cbcb23b83099658757aaafbf91de7cb","time":{"start":1759842576571,"stop":1759842580870,"duration":4299},"status":"failed","statusMessage":"AssertionError: ❌ Data completeness check failed for source_doctors ↔ stage_doctors. Missing rows = 40016","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x000001BE3C87CAD0>\nstage_db = <utils.db_helper.DBHelper object at 0x000001BE3C87D0F0>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001BE3CC8A580>\n\n    @pytest.mark.skipif(not should_run(\"scd_validation_cross_env_SourceToStage\"), reason=\"Marked N in Excel\")\n    def test_scd_StoS_validation(source_db, stage_db, report_helper):\n        validator = SCD_Validation_SourceToStage()\n>       validator.run(source_db, stage_db, report_helper)\n\ntests\\test_smoke_suite.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <src.scd_validation_cross_env.SCD_Validation_SourceToStage object at 0x000001BE3C8782F0>\nsource_db = <utils.db_helper.DBHelper object at 0x000001BE3C87CAD0>\nstage_db = <utils.db_helper.DBHelper object at 0x000001BE3C87D0F0>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001BE3CC8A580>\n\n    def run(self, source_db, stage_db, report_helper):\n        df = pd.read_excel(self.excel_path, sheet_name=\"Table_Mapping\")\n    \n        results = []\n        failed_checks = []  # track failures\n    \n        for _, row in df.iterrows():\n            source_table = row[\"source_table\"]\n            stage_table = row[\"stage_table\"]\n    \n            common_columns = self.get_common_columns(source_db, stage_db,source_table, stage_table)\n            print(f\"Common columns for {source_table} ↔ {stage_table}: {common_columns}\")\n    \n            if not common_columns:\n                logging.warning(f\"No common columns found for {source_table} ↔ {stage_table}\")\n                continue\n    \n            # ✅ Added IS_Current=1 filter for Stage DB\n            SCD_query = f\"\"\"\n                SELECT COUNT(*) AS Missing_Count\n                FROM (\n                    SELECT {common_columns}\n                    FROM {self.config.get(\"SOURCEDB\", \"database\")}.dbo.{source_table}\n                    EXCEPT\n                    SELECT {common_columns}\n                    FROM {self.config.get(\"STAGEDB\", \"database\")}.dbo.{stage_table}\n                    WHERE Is_Current='TRUE' OR Is_Current='1'\n                ) AS diff\n            \"\"\"\n    \n            logging.info(f\"Running SCD check: {source_table} → {stage_table}\")\n            raw_result = source_db.execute_query(SCD_query)\n    \n            missing_count = raw_result[0][0] if raw_result else 0\n            is_check_passed = missing_count == 0\n    \n            results.append({\n                \"Source_DB\": self.config.get(\"SOURCEDB\", \"database\"),\n                \"Source_Table\": source_table,\n                \"Stage_DB\": self.config.get(\"STAGEDB\", \"database\"),\n                \"Stage_Table\": stage_table,\n                \"Common_Columns\": common_columns,\n                \"Data_Missing_Count\": missing_count,\n                \"IsCheckPassed\": is_check_passed\n            })\n    \n            if not is_check_passed:\n                failed_checks.append(f\"❌ Data completeness check failed for {source_table} ↔ {stage_table}. Missing rows = {missing_count}\")\n    \n            # assert is_check_passed, f\"❌ SCD check failed for {source_table} ↔ {stage_table}\"\n    \n        # ✅ Save & print report\n        report_helper.save_report(results, test_type=\"SCD_Data_Check_Source_to_Stage\")\n        # self.report_helper.print_validation_report_Source_to_Stage(results)\n    \n        # ✅ Fail test only at the end (after report generation)\n>       assert not failed_checks, \"\\n\".join(failed_checks)\n               ^^^^^^^^^^^^^^^^^\nE       AssertionError: ❌ Data completeness check failed for source_doctors ↔ stage_doctors. Missing rows = 40016\n\nsrc\\scd_validation_cross_env.py:102: AssertionError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"_session_faker","time":{"start":1759842538097,"stop":1759842538197,"duration":100},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"source_db","time":{"start":1759842576568,"stop":1759842576569,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"stage_db","time":{"start":1759842576569,"stop":1759842576570,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"report_helper","time":{"start":1759842576570,"stop":1759842576571,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false}],"testStage":{"status":"failed","statusMessage":"AssertionError: ❌ Data completeness check failed for source_doctors ↔ stage_doctors. Missing rows = 40016","statusTrace":"source_db = <utils.db_helper.DBHelper object at 0x000001BE3C87CAD0>\nstage_db = <utils.db_helper.DBHelper object at 0x000001BE3C87D0F0>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001BE3CC8A580>\n\n    @pytest.mark.skipif(not should_run(\"scd_validation_cross_env_SourceToStage\"), reason=\"Marked N in Excel\")\n    def test_scd_StoS_validation(source_db, stage_db, report_helper):\n        validator = SCD_Validation_SourceToStage()\n>       validator.run(source_db, stage_db, report_helper)\n\ntests\\test_smoke_suite.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <src.scd_validation_cross_env.SCD_Validation_SourceToStage object at 0x000001BE3C8782F0>\nsource_db = <utils.db_helper.DBHelper object at 0x000001BE3C87CAD0>\nstage_db = <utils.db_helper.DBHelper object at 0x000001BE3C87D0F0>\nreport_helper = <utils.report_helper.ReportHelper object at 0x000001BE3CC8A580>\n\n    def run(self, source_db, stage_db, report_helper):\n        df = pd.read_excel(self.excel_path, sheet_name=\"Table_Mapping\")\n    \n        results = []\n        failed_checks = []  # track failures\n    \n        for _, row in df.iterrows():\n            source_table = row[\"source_table\"]\n            stage_table = row[\"stage_table\"]\n    \n            common_columns = self.get_common_columns(source_db, stage_db,source_table, stage_table)\n            print(f\"Common columns for {source_table} ↔ {stage_table}: {common_columns}\")\n    \n            if not common_columns:\n                logging.warning(f\"No common columns found for {source_table} ↔ {stage_table}\")\n                continue\n    \n            # ✅ Added IS_Current=1 filter for Stage DB\n            SCD_query = f\"\"\"\n                SELECT COUNT(*) AS Missing_Count\n                FROM (\n                    SELECT {common_columns}\n                    FROM {self.config.get(\"SOURCEDB\", \"database\")}.dbo.{source_table}\n                    EXCEPT\n                    SELECT {common_columns}\n                    FROM {self.config.get(\"STAGEDB\", \"database\")}.dbo.{stage_table}\n                    WHERE Is_Current='TRUE' OR Is_Current='1'\n                ) AS diff\n            \"\"\"\n    \n            logging.info(f\"Running SCD check: {source_table} → {stage_table}\")\n            raw_result = source_db.execute_query(SCD_query)\n    \n            missing_count = raw_result[0][0] if raw_result else 0\n            is_check_passed = missing_count == 0\n    \n            results.append({\n                \"Source_DB\": self.config.get(\"SOURCEDB\", \"database\"),\n                \"Source_Table\": source_table,\n                \"Stage_DB\": self.config.get(\"STAGEDB\", \"database\"),\n                \"Stage_Table\": stage_table,\n                \"Common_Columns\": common_columns,\n                \"Data_Missing_Count\": missing_count,\n                \"IsCheckPassed\": is_check_passed\n            })\n    \n            if not is_check_passed:\n                failed_checks.append(f\"❌ Data completeness check failed for {source_table} ↔ {stage_table}. Missing rows = {missing_count}\")\n    \n            # assert is_check_passed, f\"❌ SCD check failed for {source_table} ↔ {stage_table}\"\n    \n        # ✅ Save & print report\n        report_helper.save_report(results, test_type=\"SCD_Data_Check_Source_to_Stage\")\n        # self.report_helper.print_validation_report_Source_to_Stage(results)\n    \n        # ✅ Fail test only at the end (after report generation)\n>       assert not failed_checks, \"\\n\".join(failed_checks)\n               ^^^^^^^^^^^^^^^^^\nE       AssertionError: ❌ Data completeness check failed for source_doctors ↔ stage_doctors. Missing rows = 40016\n\nsrc\\scd_validation_cross_env.py:102: AssertionError","steps":[],"attachments":[{"uid":"2694c5a0883a806","name":"stdout","source":"2694c5a0883a806.txt","type":"text/plain","size":403}],"parameters":[],"attachmentStep":false,"hasContent":true,"stepsCount":0,"attachmentsCount":1,"shouldDisplayMessage":true},"afterStages":[{"name":"stage_db::0","time":{"start":1759842580880,"stop":1759842580881,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false},{"name":"source_db::0","time":{"start":1759842580881,"stop":1759842580882,"duration":1},"status":"passed","steps":[],"attachments":[],"parameters":[],"attachmentStep":false,"hasContent":false,"stepsCount":0,"attachmentsCount":0,"shouldDisplayMessage":false}],"labels":[{"name":"parentSuite","value":"tests"},{"name":"suite","value":"test_smoke_suite"},{"name":"host","value":"INATS-LTP-066"},{"name":"thread","value":"37152-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"tests.test_smoke_suite"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":true,"retry":true,"extra":{"categories":[],"tags":[]},"source":"84f73dafa54af6e6.json","parameterValues":[]}